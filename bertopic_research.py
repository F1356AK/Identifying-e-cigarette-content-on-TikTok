# -*- coding: utf-8 -*-
"""BERTopic_research.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jr_n-nQr2gU1T_s1aw-OtYUEaHJ5eHmK
"""

!pip install bertopic

!pip install --upgrade joblib==1.1.0

import pandas as pd
english_text = pd.read_csv('/content/BERTdesc_cleaned.csv')["description"].tolist()

english_text

import string
import nltk
nltk.download('stopwords')
import re

def text_proc(text):
    # remove links, remove retweet, remove punctuation, lowercase, remove stopwords
    # remove numbers
    # no_link = re.sub(r'^https?:\/\/.*[\r\n]*', '', text, flags=re.MULTILINE)
    no_link = re.sub(r'http\S+', '', text, flags=re.MULTILINE)
    tweet = no_link.replace("RT","")
    no_punc = "".join([i for i in tweet if i not in string.punctuation])
    punc_lower = no_punc.lower()
    # clean = ' '.join([word for word in punc_lower.split() if word not in stopwords])
    no_nums = ''.join(i for i in punc_lower if not i.isdigit())
    all_short = ' '.join([w for w in no_nums.split() if len(w)<10 and len(w)>2])

    return all_short

clean_text = []
for text in english_text:
    clean_text.append(text_proc(text))

english_text = [i for i in clean_text if i]

!pip install flair

from bertopic import BERTopic
import pandas as pd

model = BERTopic(language="english", nr_topics = 18)
topics, probs = model.fit_transform(english_text)
print(model.get_topic_info())

result = model.get_topic_info()

info_details = []
for x in range(len(result)):
    info_details.append(model.get_topic(x))

for y in range(18):
  topic = model.get_topic(y)
  df = pd.DataFrame(topic)
  df.to_csv('./Topic_' + str(y+1) + '.csv', index=False, header = ['word', 'c-TF-IDF score'])

df2 = pd.DataFrame(model.get_topic_info())
df2.to_csv('./all_18.csv', index = False)

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel

topic_model = model
cleaned_docs = english_text

# Extract vectorizer and analyzer from BERTopic
vectorizer = topic_model.vectorizer_model
analyzer = vectorizer.build_analyzer()

# Extract features for Topic Coherence evaluation
words = vectorizer.get_feature_names()
tokens = [analyzer(doc) for doc in cleaned_docs]
dictionary = corpora.Dictionary(tokens)
corpus = [dictionary.doc2bow(token) for token in tokens]
topic_words = topic_words = [[words for words, _ in topic_model.get_topic(topic) if words!='']
               for topic in range(len(set(topics))-1)]
# Evaluate
coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='u_mass')
coherence = coherence_model.get_coherence()

print(coherence)

import gensim
from bertopic import BERTopic
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
newCoherenceDF = pd.DataFrame(columns = ['# of topics', 'Coherence score'])

# This is to keep track of the number of topics to score ratio
topicNumbers = []
coherenceScores = []

for i in range(0,11):
  if i == 0:
    continue
  numTopics = i * 25
  model = BERTopic(language = 'english', nr_topics = numTopics)
  topics, probs = model.fit_transform(english_text)

  topic_model = model
  cleaned_docs = english_text

  # Extract vectorizer and analyzer from BERTopic
  vectorizer = topic_model.vectorizer_model
  analyzer = vectorizer.build_analyzer()

  # Extract features for Topic Coherence evaluation
  words = vectorizer.get_feature_names()
  tokens = [analyzer(doc) for doc in cleaned_docs]
  dictionary = corpora.Dictionary(tokens)
  corpus = [dictionary.doc2bow(token) for token in tokens]
  topic_words = topic_words = [[words for words, _ in topic_model.get_topic(topic) if words!='']
               for topic in range(len(set(topics))-1)]
  # Evaluate
  coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='c_uci')
  coherence = coherence_model.get_coherence()
  topicNumbers.append(numTopics)
  coherenceScores.append(coherence)

newCoherenceDF['Coherence score'] = coherenceScores
newCoherenceDF['# of topics'] = topicNumbers

import matplotlib.pyplot as plt

plt.plot(newCoherenceDF['# of topics'], newCoherenceDF['Coherence score'])
plt.xlabel('Number of topics')
plt.ylabel('Coherence score')
plt.title('c_uci')
plt.show()

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
from bertopic import BERTopic

# This is to keep track of the number of topics to score ratio for 0-25 topics
topicNumbers25 = []
coherenceScores25 = []

for i in range(0,26):
  if i == 0:
    continue
  numTopics = i
  model = BERTopic(language = 'english', nr_topics = numTopics)
  topics, probs = model.fit_transform(english_text)

  topic_model = model
  cleaned_docs = english_text

  # Extract vectorizer and analyzer from BERTopic
  vectorizer = topic_model.vectorizer_model
  analyzer = vectorizer.build_analyzer()

  # Extract features for Topic Coherence evaluation
  words = vectorizer.get_feature_names()
  tokens = [analyzer(doc) for doc in cleaned_docs]
  dictionary = corpora.Dictionary(tokens)
  corpus = [dictionary.doc2bow(token) for token in tokens]
  topic_words = topic_words = [[words for words, _ in topic_model.get_topic(topic) if words!='']
               for topic in range(len(set(topics))-1)]
  # Evaluate
  coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='u_mass')
  coherence = coherence_model.get_coherence()
  topicNumbers25.append(numTopics)
  coherenceScores25.append(coherence)

newCoherenceDF25 = pd.DataFrame(columns = ['# of topics', 'Coherence score'])

newCoherenceDF25['Coherence score'] = coherenceScores25
newCoherenceDF25['# of topics'] = topicNumbers25

print(newCoherenceDF25)

import matplotlib.pyplot as plt
plt.plot(newCoherenceDF25['# of topics'], newCoherenceDF25['Coherence score'])
plt.xlabel('Number of topics')
plt.ylabel('Coherence score')
plt.title('u_mass')
plt.show()

newCoherenceDF25

newCoherenceDF

"""## **Below are the visualization outputs of the 18 topic run, including td-idf score bar charts, intertopic distance map, and other built in BERTopic visualizations.**"""

from bertopic import BERTopic

model = BERTopic(language="english", nr_topics=19)
topics, probs = model.fit_transform(english_text)
print(model.get_topic_info())

"""Td-idf score bar charts"""

model.visualize_barchart()

""" Intertopic distance map"""

model.visualize_topics()

"""Hierarchical charts"""

model.visualize_hierarchy()

"""Similarity matrices"""

model.visualize_heatmap()

"""Term score decline"""

model.visualize_term_rank()